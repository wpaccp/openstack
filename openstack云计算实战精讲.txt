                                 openstack云计算实战精讲
一键安装openstack p版
[root@controller ~]#iptables -L
[root@controller ~]#systemctl status firewall.service 
[root@controller ~]#vim /etc/hosts
[root@controller ~]#cat /etc/hostname
controller
[root@controller ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.100.152 controller
cat /etc/hostname
reboot
[root@controller ~]# systemctl stop NetworkManager
[root@controller ~]# systemctl disable NetworkManager
[root@controller ~]# systemctl enable network
[root@controller ~]# yum update device-mapper
[root@controller ~]# yum install -y http://rdo.fedorapeople.org/rdo-release.rpm
[root@controller ~]# yum install -y openstack-packstack
[root@controller ~]# packstack --allinone
Welcome to the Packstack setup utility

The installation log file is available at: /var/tmp/packstack/20171005-191936-qcPxBi/openstack-setup.log
Packstack changed given value  to required value /root/.ssh/id_rsa.pub

Installing:
Clean Up                                             [ DONE ]
Discovering ip protocol version                      [ DONE ]
Setting up ssh keys                                  [ DONE ]
Preparing servers                                    [ DONE ]
Pre installing Puppet and discovering hosts' details [ DONE ]
Preparing pre-install entries                        [ DONE ]
Setting up CACERT                                    [ DONE ]
Preparing AMQP entries                               [ DONE ]
Preparing MariaDB entries                            [ DONE ]
Fixing Keystone LDAP config parameters to be undef if empty[ DONE ]
Preparing Keystone entries                           [ DONE ]
Preparing Glance entries                             [ DONE ]
Checking if the Cinder server has a cinder-volumes vg[ DONE ]
Preparing Cinder entries                             [ DONE ]
Preparing Nova API entries                           [ DONE ]
Creating ssh keys for Nova migration                 [ DONE ]
Gathering ssh host keys for Nova migration           [ DONE ]
Preparing Nova Compute entries                       [ DONE ]
Preparing Nova Scheduler entries                     [ DONE ]
Preparing Nova VNC Proxy entries                     [ DONE ]
Preparing OpenStack Network-related Nova entries     [ DONE ]
Preparing Nova Common entries                        [ DONE ]
Preparing Neutron LBaaS Agent entries                [ DONE ]
Preparing Neutron API entries                        [ DONE ]
Preparing Neutron L3 entries                         [ DONE ]
Preparing Neutron L2 Agent entries                   [ DONE ]
Preparing Neutron DHCP Agent entries                 [ DONE ]
Preparing Neutron Metering Agent entries             [ DONE ]
Checking if NetworkManager is enabled and running    [ DONE ]
Preparing OpenStack Client entries                   [ DONE ]
Preparing Horizon entries                            [ DONE ]
Preparing Swift builder entries                      [ DONE ]
Preparing Swift proxy entries                        [ DONE ]
Preparing Swift storage entries                      [ DONE ]
Preparing Gnocchi entries                            [ DONE ]
Preparing MongoDB entries                            [ DONE ]
Preparing Redis entries                              [ DONE ]
Preparing Ceilometer entries                         [ DONE ]
Preparing Aodh entries                               [ DONE ]
Preparing Puppet manifests                           [ DONE ]
Copying Puppet modules and manifests                 [ DONE ]
Applying 192.168.100.152_controller.pp
192.168.100.152_controller.pp:                       [ DONE ]            
Applying 192.168.100.152_network.pp
192.168.100.152_network.pp:                          [ DONE ]         
Applying 192.168.100.152_compute.pp
192.168.100.152_compute.pp:                          [ DONE ]         
Applying Puppet manifests                            [ DONE ]
Finalizing                                           [ DONE ]

 **** Installation completed successfully ******

Additional information:
 * A new answerfile was created in: /root/packstack-answers-20171005-191936.txt
 * Time synchronization installation was skipped. Please note that unsynchronized time on server instances might be problem for some OpenStack components.
 * File /root/keystonerc_admin has been created on OpenStack client host 192.168.100.152. To use the command line tools you need to source the file.
 * To access the OpenStack Dashboard browse to http://192.168.100.152/dashboard .
Please, find your login credentials stored in the keystonerc_admin in your home directory.
 * The installation log file is available at: /var/tmp/packstack/20171005-191936-qcPxBi/openstack-setup.log
 * The generated manifests are available at: /var/tmp/packstack/20171005-191936-qcPxBi/manifest

 
[root@controller ~]# cat keystonerc_admin 
unset OS_SERVICE_TOKEN
    export OS_USERNAME=admin
    export OS_PASSWORD='6ef6d03c98184408'
    export OS_AUTH_URL=http://192.168.100.152:5000/v3
    export PS1='[\u@\h \W(keystone_admin)]\$ '
    
export OS_PROJECT_NAME=admin
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_DOMAIN_NAME=Default
export OS_IDENTITY_API_VERSION=3
[root@controller ~]# cat keystonerc_demo 
unset OS_SERVICE_TOKEN
export OS_USERNAME=demo
export OS_PASSWORD='79f39972bde24311'
export PS1='[\u@\h \W(keystone_demo)]\$ '
export OS_AUTH_URL=http://192.168.100.152:5000/v3
    
export OS_PROJECT_NAME=demo
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_DOMAIN_NAME=Default
export OS_IDENTITY_API_VERSION=3

#openstack官方镜像文件下载地址
http://cloud.centos.org/centos/6/images/
http://cloud.centos.org/centos/7/images/

#openstack下载地址
https://mirrors.aliyun.com/centos/7.4.1708/cloud/x86_64/

#centos 7.4下载地址
http://mirrors.tuna.tsinghua.edu.cn/centos/7/isos/x86_64/CentOS-7-x86_64-Minimal-1708.iso 
http://mirrors.tuna.tsinghua.edu.cn/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-1708.iso 

创建虚拟机错误的问题点归纳
1)时间要同步正确
2)数据库必须是正常运行的
3)rabbitmq服务必须是正常运行的

网络调试演示
[root@linux-node1 ~]# source admin-openstack.sh 
[root@linux-node1 ~]# scp demo-openstack.sh root@192.168.100.152:/root/
root@192.168.100.152's password: 
demo-openstack.sh                                             100%  262     0.3KB/s   00:00    
[root@linux-node1 ~]# neutron net-list
neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead.
+--------------------------------------+-------------+----------------------------------+-------------------------------------------------------+
| id                                   | name        | tenant_id                        | subnets                                               |
+--------------------------------------+-------------+----------------------------------+-------------------------------------------------------+
| 0c1ab9c0-367a-42ad-948d-7946d22d018d | selfservice | f89b984da28c42b192bd7d5f8d2c28ec | 697fb979-f485-40d3-8754-8344812ceb1d 172.16.1.0/24    |
| 2405cba1-a734-4bef-99e4-f6d19bc46b6b | provider    | 71abd209193a4959a03afaf93165c6b3 | ed9c04b2-dbe3-4ec2-88ea-93e0c6d18312 192.168.100.0/24 |
| 96e649b6-4111-4c49-b96b-f1a027d84c0f | selfservice | 71abd209193a4959a03afaf93165c6b3 | aa5d4709-2be9-4fbe-ab62-7f195b2e9bba 172.16.1.0/24    |
+--------------------------------------+-------------+----------------------------------+-------------------------------------------------------+
[root@linux-node1 ~]# ip netns | grep 96e649b6
qdhcp-96e649b6-4111-4c49-b96b-f1a027d84c0f
[root@linux-node1 ~]# ip netns exec qdhcp-96e649b6-4111-4c49-b96b-f1a027d84c0f ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: ns-8b4df2ba-9f@if9: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc pfifo_fast state UP qlen 1000
    link/ether fa:16:3e:fe:3a:53 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 169.254.169.254/16 brd 169.254.255.255 scope global ns-8b4df2ba-9f
       valid_lft forever preferred_lft forever
    inet 172.16.1.2/24 brd 172.16.1.255 scope global ns-8b4df2ba-9f
       valid_lft forever preferred_lft forever
    inet6 fe80::f816:3eff:fefe:3a53/64 scope link 
       valid_lft forever preferred_lft forever
[root@linux-node1 ~]# ip nets | grep  2405cba1
Object "nets" is unknown, try "ip help".
[root@linux-node1 ~]# ip nets | grep 2405cba1
Object "nets" is unknown, try "ip help".
[root@linux-node1 ~]# ip netns | grep 2405cba1
qdhcp-2405cba1-a734-4bef-99e4-f6d19bc46b6b
[root@linux-node1 ~]# ip netns qdhcp-2405cba1-a734-4bef-99e4-f6d19bc46b6b
Command "qdhcp-2405cba1-a734-4bef-99e4-f6d19bc46b6b" is unknown, try "ip netns help".
[root@linux-node1 ~]# ip netns qdhcp-2405cba1-a734-4bef-99e4-f6d19bc46b6b ip a
Command "qdhcp-2405cba1-a734-4bef-99e4-f6d19bc46b6b" is unknown, try "ip netns help".
[root@linux-node1 ~]# ip netns exec qdhcp-2405cba1-a734-4bef-99e4-f6d19bc46b6b ip a
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN 
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: ns-97f53240-57@if3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP qlen 1000
    link/ether fa:16:3e:64:d2:b9 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 192.168.100.220/24 brd 192.168.100.255 scope global ns-97f53240-57
       valid_lft forever preferred_lft forever
    inet 169.254.169.254/16 brd 169.254.255.255 scope global ns-97f53240-57
       valid_lft forever preferred_lft forever
    inet6 fe80::f816:3eff:fe64:d2b9/64 scope link 
       valid_lft forever preferred_lft forever
[root@linux-node1 ~]# ip netns exec qdhcp-2405cba1-a734-4bef-99e4-f6d19bc46b6b netstat -anlp
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      26867/haproxy       
tcp        0      0 192.168.100.220:53      0.0.0.0:*               LISTEN      61900/dnsmasq       
tcp        0      0 169.254.169.254:53      0.0.0.0:*               LISTEN      61900/dnsmasq       
tcp6       0      0 fe80::f816:3eff:fe64:53 :::*                    LISTEN      61900/dnsmasq       
udp        0      0 192.168.100.220:53      0.0.0.0:*                           61900/dnsmasq       
udp        0      0 169.254.169.254:53      0.0.0.0:*                           61900/dnsmasq       
udp        0      0 0.0.0.0:67              0.0.0.0:*                           61900/dnsmasq       
udp6       0      0 fe80::f816:3eff:fe64:53 :::*                                61900/dnsmasq       
Active UNIX domain sockets (servers and established)
Proto RefCnt Flags       Type       State         I-Node   PID/Program name     Path
unix  2      [ ]         DGRAM                    83947    26867/haproxy        
unix  2      [ ]         DGRAM                    1385855  61900/dnsmasq        
[root@linux-node1 ~]# ip netns exec qdhcp-2405cba1-a734-4bef-99e4-f6d19bc46b6b netstat -tnlp
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      26867/haproxy       
tcp        0      0 192.168.100.220:53      0.0.0.0:*               LISTEN      61900/dnsmasq       
tcp        0      0 169.254.169.254:53      0.0.0.0:*               LISTEN      61900/dnsmasq       
tcp6       0      0 fe80::f816:3eff:fe64:53 :::*                    LISTEN      61900/dnsmasq       
[root@linux-node1 ~]# ip netns exec qdhcp-2405cba1-a734-4bef-99e4-f6d19bc46b6b netstat -anlp
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      26867/haproxy       
tcp        0      0 192.168.100.220:53      0.0.0.0:*               LISTEN      61900/dnsmasq       
tcp        0      0 169.254.169.254:53      0.0.0.0:*               LISTEN      61900/dnsmasq       
tcp6       0      0 fe80::f816:3eff:fe64:53 :::*                    LISTEN      61900/dnsmasq       
udp        0      0 192.168.100.220:53      0.0.0.0:*                           61900/dnsmasq       
udp        0      0 169.254.169.254:53      0.0.0.0:*                           61900/dnsmasq       
udp        0      0 0.0.0.0:67              0.0.0.0:*                           61900/dnsmasq       
udp6       0      0 fe80::f816:3eff:fe64:53 :::*                                61900/dnsmasq       
Active UNIX domain sockets (servers and established)
Proto RefCnt Flags       Type       State         I-Node   PID/Program name     Path
unix  2      [ ]         DGRAM                    83947    26867/haproxy        
unix  2      [ ]         DGRAM                    1385855  61900/dnsmasq

nova命令
nova flavor-list:显示虚拟机模板信息
nova image-list:显示镜像信息
nova secgroup-list:显示当前安全组信息
nova keypair-list:显示当前密钥信息
neutron net-list:显示网络信息
nova list:显示创建的实例信息
cinder list:查看volumn挂载的信息

一次openstack的排错
1.故障现象：
openstack平台反应速度慢。执行各种创建删除操作极其卡顿。
2.解决思路：
openstack的各个组件之间是依靠rabbitmq解耦。判断rabbitmq出现问题。
3.具体操作
3.1在rabbitmq执行
$ watch -n2 "rabbitmqctl list_connections channels name | sort -k1,1nr | head -20"
执行结果：
Every 2.0s: rabbitmqctl list_connections channels name | sort -k1,1nr | head -20
Mon Feb 29 10:16:45 2017
1087 10.0.10.17:32803 -> 10.0.10.10:5672
1822 10.0.10.17:33315 -> 10.0.10.10:5672
"1087 10.0.10.17:32844 -> 10.0.10.10:5672" 表示："10.0.10.17:32803 -> 10.0.10.10:5672"这个connection，一共创建了1087个channel
3.2然后登陆rabbmq-web界面通过connection可以定位channel通过channel定位openstack组件。
3.3本次是neutron-l3-agent出现问题执行systemctl restart neutron-l3-agent.service

二次openstack排错
1.故障现象：
云平台各种操作，反应变慢。（好像和上次一样）
2.解决思路：
消息不断堆积，而无消费者消费消息，会消耗资源，从而触发rabbitmq的拥塞控制机制，降低生产者向rbbitmq发送消息的速率（好像还和上次一样）
3.查询故障
一个cinder-scheduler 进程对应一个cinder-scheduler_fanout_{uuid}队列。我们现有两个api
节点，含有两个cinder-scheduler进程，对应两个cinder-scheduler_fanout_{uuid}队列，如下所示，含有三个队列，说明有一个僵尸队列。（一
般是堆积消息的队列为僵尸队列）
$ rabbitmqctl list_queues |grep cinder-scheduler
cinder-scheduler 0
cinder-scheduler.cinder 0
cinder-scheduler_fanout_5720c0511f654740bb639de7282a3ed1 48
cinder-scheduler_fanout_89ec86c1f9ce404089d17e6825050555 0
cinder-scheduler_fanout_ee07d2cb126c4378b59bf11007aa879b 0
查询队列对应的consume
$ rabbitmqctl list_consumers |grep cinder-scheduler_fanout_
cinder-scheduler_fanout_89ec86c1f9ce404089d17e6825050555 <rabbit@server-52.1.7565.33> 3 true 0 []
cinder-scheduler_fanout_ee07d2cb126c4378b59bf11007aa879b <rabbit@server-53.3.12569.78> 3 true 0 []
此时发现cinder-scheduler_fanout_5720c0511f654740bb639de7282a3ed1 这个队列没有consume，确认此queue为僵尸队列。
一个组件突然断掉，当期再次加入集群中时 ，不是复用原先的队列，而是创建新的队列。而原来的队列依然绑定在exchange上，这样，从exchange
路由过来的消息依然会发送到老队列上，老队列上没有“consumer”与之对应，导致消息队列的堆积。
4.故障解决 
删除该僵尸队列
rabbitmqadmin delete queue name='xxxx'




















